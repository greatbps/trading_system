#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
trading_system/data_collectors/news_collector.py

ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ì¬ë£Œ ë¶„ì„ í´ë˜ìŠ¤ (ê°œì„ ëœ ë²„ì „)
"""

import time
import requests
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta
import json
from bs4 import BeautifulSoup
import urllib.parse
import sys
from pathlib import Path
import asyncio
import aiohttp
from core.trading_system import AnalysisResult, StockData

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.logger import get_logger
from analyzers.gemini_analyzer import GeminiAnalyzer

# ================================
# ì¬ë£Œ ë¶„ë¥˜ í‚¤ì›Œë“œ ë° ê°€ì¤‘ì¹˜
# ================================
MATERIAL_KEYWORDS = {
    "ì¥ê¸°ì¬ë£Œ": {
        "keywords": [
            # ê²½ì˜ê¶Œ/ì§€ë°°êµ¬ì¡°
            "ê²½ì˜ê¶Œë³€í™”", "ëŒ€ì£¼ì£¼ë³€ê²½", "ê²½ì˜ì§„êµì²´", "ì˜¤ë„ˆêµì²´", "ìŠ¹ê³„", "ì„¸ëŒ€êµì²´",
            "ì§€ë°°êµ¬ì¡°ê°œì„ ", "ê±°ë²„ë„ŒìŠ¤", "íˆ¬ëª…ê²½ì˜", "ì „ë¬¸ê²½ì˜ì¸", "ì‚¬ì™¸ì´ì‚¬", "ë…ë¦½ì´ì‚¬",
            "ìµœëŒ€ ì£¼ì£¼", "ì£¼ìš” ì£¼ì£¼", "ê²½ì˜ê¶Œ", "í•µì‹¬ ì¸ì¬", "ê²½ì˜ì§„",
            
            # ESG ê²½ì˜
            "ESG", "ESGê²½ì˜", "ì§€ì†ê°€ëŠ¥ê²½ì˜", "ì¹œí™˜ê²½", "íƒ„ì†Œì¤‘ë¦½", "ê·¸ë¦°ê²½ì˜", "ì‚¬íšŒê³µí—Œ",
            "ìœ¤ë¦¬ê²½ì˜", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "í™˜ê²½ë³´í˜¸", "ì¬ìƒì—ë„ˆì§€", "ì¹œí™˜ê²½ì œí’ˆ", "ë…¹ìƒ‰ê¸°ìˆ ",
            
            # ë°°ë‹¹ì •ì±…
            "ë°°ë‹¹ì •ì±…", "ë°°ë‹¹í™•ëŒ€", "ì£¼ì£¼ì¹œí™”ì •ì±…", "ë°°ë‹¹ì„±í–¥", "ì•ˆì •ë°°ë‹¹", "ëˆ„ì§„ë°°ë‹¹",
            "íŠ¹ë³„ë°°ë‹¹", "ì¤‘ê°„ë°°ë‹¹", "ë¶„ê¸°ë°°ë‹¹", "ì£¼ì£¼í™˜ì›ì •ì±…", "ì£¼ì£¼ê°€ì¹˜ì œê³ ", "ë°°ë‹¹",
            "ìì‚¬ì£¼ ë§¤ì…", "ë¶€ì±„ ìƒí™˜", "ìì‚¬ì£¼ ì†Œê°", "ì•¡ë©´ë¶„í• ",
            
            # ì‹ ì„±ì¥ë™ë ¥
            "ì‹ ì„±ì¥ë™ë ¥", "ë¯¸ë˜ë¨¹ê±°ë¦¬", "ì°¨ì„¸ëŒ€ì‚¬ì—…", "4ì°¨ì‚°ì—…í˜ëª…", "ë””ì§€í„¸ì „í™˜", "DX",
            "ì¸ê³µì§€ëŠ¥", "AI", "ë¹…ë°ì´í„°", "í´ë¼ìš°ë“œ", "IoT", "ë¡œë´‡", "ììœ¨ì£¼í–‰", "ì „ê¸°ì°¨",
            "ë°°í„°ë¦¬", "ë°”ì´ì˜¤", "í—¬ìŠ¤ì¼€ì–´", "ì‹ ì¬ìƒì—ë„ˆì§€", "ìˆ˜ì†Œ", "ë©”íƒ€ë²„ìŠ¤", "ë¸”ë¡ì²´ì¸",
            "ì‹ ì„±ì¥ ë™ë ¥", "ì „ëµì  ì œíœ´",
            
            # ì¥ê¸° íŠ¸ë Œë“œ
            "ë©”ê°€íŠ¸ë Œë“œ", "êµ¬ì¡°ì ì„±ì¥", "ì¥ê¸°ì„±ì¥", "ì§€ì†ì„±ì¥", "ì•ˆì •ì„±ì¥", "ì„±ì¥ì§€ì†ì„±",
            "ì¥ê¸°ìˆ˜ìµì„±", "ì§€ì†ê°€ëŠ¥ì„±", "ì¥ê¸°ì „ë§", "ì¤‘ì¥ê¸°ê³„íš", "ë¹„ì „2030", "ì¥ê¸°ëª©í‘œ",
            "ë‹¨ì¼ íŒë§¤", "ê³µê¸‰ê³„ì•½", "ìœ í˜•ìì‚°", "ìƒì‚°ì„¤ë¹„"
        ],
        "weight": 3.0  # ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
    },
    
    "ì¤‘ê¸°ì¬ë£Œ": {
        "keywords": [
            # ì‚°ì—…/ì‹œì¥ ë™í–¥
            "ì‚°ì—…ì„±ì¥", "ì‹œì¥í™•ëŒ€", "ì‹œì¥ì ìœ ìœ¨", "ì—…ê³„1ìœ„", "ê¸€ë¡œë²Œì‹œì¥", "í•´ì™¸ì§„ì¶œ",
            "ìˆ˜ì¶œì¦ê°€", "ë‚´ìˆ˜íšŒë³µ", "ê²½ê¸°íšŒë³µ", "ì—…í™©ê°œì„ ", "ìˆ˜ìš”ì¦ê°€", "ê³µê¸‰ë¶€ì¡±",
            "ê°€ê²©ìƒìŠ¹", "ë§ˆì§„ê°œì„ ", "ì›ê°€ì ˆê°", "ì‚°ì—… í˜¸í™©", "ëŒ€ê·œëª¨ ìˆ˜ì£¼",
            
            # ê¸°ìˆ ìš°ìœ„/ê²½ìŸë ¥
            "ê¸°ìˆ ìš°ìœ„", "ê²½ìŸë ¥ê°•í™”", "ì°¨ë³„í™”ê¸°ìˆ ", "ë…ì ê¸°ìˆ ", "ì›ì²œê¸°ìˆ ë³´ìœ ", "ê¸°ìˆ ê²©ì°¨",
            "ê³ ë¶€ê°€ê°€ì¹˜", "í”„ë¦¬ë¯¸ì—„ì œí’ˆ", "ê¸°ìˆ í˜ì‹ ", "R&Díˆ¬ì", "ì—°êµ¬ê°œë°œ", "ê¸°ìˆ ê°œë°œ",
            "ê¸°ìˆ ë ¥ ìš°ìˆ˜", "ë°˜ì‚¬ì´ìµ",
            
            # í„´ì–´ë¼ìš´ë“œ
            "í„´ì–´ë¼ìš´ë“œ", "ì‹¤ì ë°˜ë“±", "íšŒë³µ", "ì •ìƒí™”", "êµ¬ì¡°ì¡°ì •ì™„ë£Œ", "ë¦¬ìŠ¤íŠ¸ëŸ­ì²˜ë§",
            "ê²½ì˜ì •ìƒí™”", "í‘ìì „í™˜", "ì ìíƒˆì¶œ", "ë¶€ì±„ê°ì¶•", "ì¬ë¬´êµ¬ì¡°ê°œì„ ", "êµ¬ì¡°ì¡°ì •",
            "ì‚¬ì—…ë¶€ ë§¤ê°", "ìˆ˜ìµì„± ê°œì„ ", "ì‚¬ì—… ì¶•ì†Œ", "ì² ìˆ˜",
            
            # í•´ì™¸ì§„ì¶œ/ê¸€ë¡œë²Œí™”
            "í•´ì™¸ì§„ì¶œ", "ê¸€ë¡œë²Œì§„ì¶œ", "í˜„ì§€ë²•ì¸", "í•´ì™¸ê³µì¥", "ìˆ˜ì¶œí™•ëŒ€", "ê¸€ë¡œë²ŒíŒŒíŠ¸ë„ˆì‹­",
            "í•´ì™¸ì¸ìˆ˜", "êµ­ì œí˜‘ë ¥", "ê¸€ë¡œë²Œë¸Œëœë“œ", "í•´ì™¸ì‹œì¥ê°œì²™", "ìˆ˜ì¶œì£¼ë ¥", "í•´ì™¸ ì§„ì¶œ",
            
            # ì‚¬ì—…êµ¬ì¡° ë³€í™”
            "ì‚¬ì—…êµ¬ì¡°ê°œì„ ", "í¬íŠ¸í´ë¦¬ì˜¤ì¬í¸", "ë¹„í•µì‹¬ì‚¬ì—…ë§¤ê°", "ì„ íƒê³¼ì§‘ì¤‘", "í•µì‹¬ì—­ëŸ‰ê°•í™”",
            "ì‚¬ì—…ë‹¤ê°í™”", "ì‹ ì„±ì¥ë™ë ¥", "ë¯¸ë˜ì‚¬ì—…", "ê³ ìˆ˜ìµì‚¬ì—…", "ì•ˆì •ì ìˆ˜ìµêµ¬ì¡°",
            "ì›ìì¬ ê°€ê²©", "ê²½ìŸì‚¬"
        ],
        "weight": 2.0  # ì¤‘ê°„ ê°€ì¤‘ì¹˜
    },
    
    "ë‹¨ê¸°ì¬ë£Œ": {
        "keywords": [
            # M&A ê´€ë ¨
            "ì¸ìˆ˜í•©ë³‘", "M&A", "ì¸ìˆ˜", "í•©ë³‘", "ë§¤ìˆ˜", "ì¸ìˆ˜ì œì•ˆ", "ì§€ë¶„ë§¤ì…", "ê²½ì˜ê¶Œì¸ìˆ˜",
            "TOB", "ìš°í˜¸ì ì¸ìˆ˜", "ì ëŒ€ì ì¸ìˆ˜", "MBO", "LBO", "ì œ3ì ë°°ì •",
            
            # ì‹¤ì  ê´€ë ¨
            "ì‹¤ì ë°œí‘œ", "ì–´ë‹ì„œí”„ë¼ì´ì¦ˆ", "ì–´ë‹ì‡¼í¬", "ë¶„ê¸°ì‹¤ì ", "ì—°ê°„ì‹¤ì ", "ë§¤ì¶œì¦ê°€", 
            "ì˜ì—…ì´ìµ", "ë‹¹ê¸°ìˆœì´ìµ", "ì‹¤ì í˜¸ì¡°", "ì‹¤ì ê°œì„ ", "ê¹œì§ì‹¤ì ", "ì»¨ì„¼ì„œìŠ¤ìƒíšŒ",
            "ê°€ì´ë˜ìŠ¤ìƒí–¥", "ì‹¤ì ì „ë§ìƒí–¥", "ì‚¬ìƒ ìµœëŒ€ ì‹¤ì ",
            
            # ì‹ ì‚¬ì—…/ì‹ ì œí’ˆ
            "ì‹ ì‚¬ì—…", "ì‹ ì œí’ˆ", "ì‹ ê¸°ìˆ ", "ì‹ ê·œì‚¬ì—…", "ì‚¬ì—…ë‹¤ê°í™”", "ì‹ ê·œì§„ì¶œ", "ì‚¬ì—…í™•ì¥",
            "ì œí’ˆì¶œì‹œ", "ìƒìš©í™”", "ì–‘ì‚°", "ëŒ€ëŸ‰ìƒì‚°", "ì œí’ˆê°œë°œì™„ë£Œ", "ì¶œì‹œì˜ˆì •", "ì‹ ê·œ ì‚¬ì—…",
            
            # ìˆ˜ì£¼/ê³„ì•½
            "ìˆ˜ì£¼", "ëŒ€í˜•ìˆ˜ì£¼", "ê³„ì•½ì²´ê²°", "ë‚©í’ˆê³„ì•½", "ê³µê¸‰ê³„ì•½", "ì¥ê¸°ê³„ì•½", "ë…ì ê³„ì•½",
            "MOU", "ì—…ë¬´í˜‘ì•½", "ì „ëµì ì œíœ´", "íŒŒíŠ¸ë„ˆì‹­", "ê³µë™ê°œë°œ", "í˜‘ë ¥ê³„ì•½", "ì‹ ê·œ ìˆ˜ì£¼",
            
            # ì •ë¶€ì •ì±…/ê·œì œ
            "ì •ë¶€ì§€ì›", "ì •ì±…ìˆ˜í˜œ", "ê·œì œì™„í™”", "ì¸í—ˆê°€", "ìŠ¹ì¸", "í—ˆê°€ì·¨ë“", "ì •ë¶€ë°œì£¼",
            "êµ­ì±…ì‚¬ì—…", "ì •ë¶€ê³¼ì œ", "R&Dì§€ì›", "ì„¸ì œí˜œíƒ", "ë³´ì¡°ê¸ˆ", "ì •ì±…ì§€ì›", "ì •ë¶€ ì •ì±…",
            
            # íŠ¹í—ˆ/ì§€ì ì¬ì‚°ê¶Œ
            "íŠ¹í—ˆ", "íŠ¹í—ˆì¶œì›", "íŠ¹í—ˆë“±ë¡", "íŠ¹í—ˆì†Œì†¡", "ë¼ì´ì„¼ìŠ¤", "ê¸°ìˆ ì´ì „", "ì§€ì ì¬ì‚°ê¶Œ",
            "íŠ¹í—ˆê¶Œ", "ì›ì²œê¸°ìˆ ", "í•µì‹¬íŠ¹í—ˆ", "êµ­ì œíŠ¹í—ˆ", "íŠ¹í—ˆí¬íŠ¸í´ë¦¬ì˜¤",
            
            # ì£¼ê°€/ì£¼ì£¼ê´€ë ¨
            "ìì‚¬ì£¼ë§¤ì…", "ë°°ë‹¹ì¦ê°€", "ë°°ë‹¹í™•ëŒ€", "ì£¼ì‹ë¶„í• ", "ì•¡ë©´ë¶„í• ", "ë¬´ìƒì¦ì",
            "ìœ ìƒì¦ì", "ì£¼ì£¼í™˜ì›", "ë°°ë‹¹ì •ì±…", "ì£¼ì£¼ê°€ì¹˜", "ìíšŒì‚¬ ìƒì¥", "ê³µê°œë§¤ìˆ˜",
            "íšŒì‚¬ ë¶„í• ", "ì¸ì ë¶„í• ", "ë¬¼ì ë¶„í• ",
            
            # ê¸°íƒ€ ë‹¨ê¸° ì´ë²¤íŠ¸
            "IPO", "ìƒì¥", "ì½”ìŠ¤ë‹¥ì´ì „", "ì½”ìŠ¤í”¼ìŠ¹ê²©", "í¸ì…", "ì‹ ê·œí¸ì…", "ì§€ìˆ˜í¸ì…",
            "ìŠ¤í•€ì˜¤í”„", "ë¶„í• ", "í•©ë³‘", "ê¸°ì—…ë¶„í• ", "ì¡°ì§ê°œí¸",
            
            # ì‹ ê¸°ìˆ /íŠ¸ë Œë“œ
            "AI", "ì¸ê³µì§€ëŠ¥", "2ì°¨ì „ì§€", "ë¡œë´‡", "ë°©ì‚°", "ì„ìƒ", "ì‹ ì•½ ê°œë°œ",
            "ê¸°ê´€ ë§¤ìˆ˜", "ì™¸êµ­ì¸ ë§¤ìˆ˜", "ì§€ë¶„ ë³€ë™", "íˆ¬ìê²½ê³ ", "ê±°ë˜ì •ì§€"
        ],
        "weight": 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
    }
}

# ì œì™¸ í‚¤ì›Œë“œ
EXCLUDE_KEYWORDS = [
    # ETF ê´€ë ¨
    "ETF", "ETN", "ìƒì¥ì§€ìˆ˜í€ë“œ", "ì¸ë²„ìŠ¤", "ë ˆë²„ë¦¬ì§€", "KODEX", "TIGER", "ARIRANG", 
    "KINDEX", "TREX", "HANARO", "TIMEFOLIO", "FOCUS", "SOL", "SMART", "PLUS",
    
    # ìš°ì„ ì£¼
    "ìš°ì„ ì£¼", "ìš°ì„ ", "1ìš°", "2ìš°", "3ìš°", "4ìš°", "5ìš°",
    
    # íˆ¬ìì£¼ì˜ ì¢…ëª©
    "ê´€ë¦¬", "ìœ„í—˜", "íˆ¬ìì£¼ì˜", "íˆ¬ìê²½ê³ ", "ê±°ë˜ì •ì§€", "ìƒì¥íì§€",
    "ê´€ë¦¬ì¢…ëª©", "íˆ¬ììœ„í—˜", "ê°ë¦¬", "ê³µì‹œ", "í•´ëª…"
]

class NewsCollector:
    """Gemini AI í†µí•© ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, config=None):
        self.config = config
        self.logger = get_logger("NewsCollector")
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
        })
        
        # ë„¤ì´ë²„ API ì„¤ì • (ìˆëŠ” ê²½ìš°)
        if config and hasattr(config.api, 'NAVER_CLIENT_ID'):
            self.naver_client_id = config.api.NAVER_CLIENT_ID
            self.naver_client_secret = config.api.NAVER_CLIENT_SECRET
        else:
            self.naver_client_id = None
            self.naver_client_secret = None
        
        # Gemini ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.gemini_analyzer = GeminiAnalyzer(config) if config else None
    
    def is_excluded_stock(self, stock_name: str, stock_code: str = "") -> bool:
        """ì œì™¸ ëŒ€ìƒ ì¢…ëª©ì¸ì§€ í™•ì¸"""
        stock_text = f"{stock_name} {stock_code}".upper()
        
        for keyword in EXCLUDE_KEYWORDS:
            if keyword.upper() in stock_text:
                self.logger.debug(f"ì œì™¸ ì¢…ëª© ë°œê²¬: {stock_name} (í‚¤ì›Œë“œ: {keyword})")
                return True
        
        return False
    
    async def search_naver_news_api(self, query: str, display: int = 10) -> List[Dict]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)"""
        if not self.naver_client_id or not self.naver_client_secret:
            return []
        
        try:
            url = "https://openapi.naver.com/v1/search/news.json"
            headers = {
                "X-Naver-Client-Id": self.naver_client_id,
                "X-Naver-Client-Secret": self.naver_client_secret
            }
            params = {
                "query": query,
                "display": display,
                "start": 1,
                "sort": "date"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        news_items = []
                        
                        for item in data.get('items', []):
                            news_item = {
                                'title': item.get('title', '').replace('<b>', '').replace('</b>', ''),
                                'link': item.get('link', ''),
                                'description': item.get('description', '').replace('<b>', '').replace('</b>', ''),
                                'pubDate': item.get('pubDate', ''),
                                'source': 'naver_api'
                            }
                            news_items.append(news_item)
                        
                        return news_items
                    
        except Exception as e:
            self.logger.warning(f"ë„¤ì´ë²„ API ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return []
    
    def search_stock_news_naver(self, stock_name: str, stock_code: str) -> List[Dict]:
        """ê°œì„ ëœ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            # ì œì™¸ ëŒ€ìƒ ì¢…ëª© ì²´í¬
            if self.is_excluded_stock(stock_name, stock_code):
                self.logger.info(f"   ğŸš« {stock_name} - ì œì™¸ ëŒ€ìƒ ì¢…ëª©")
                return []
            
            self.logger.info(f"   ğŸ” ë„¤ì´ë²„ì—ì„œ {stock_name} ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
            
            search_queries = [
                stock_name,
                f"{stock_name} ì£¼ì‹",
                f"{stock_name} ê¸°ì—…",
                stock_code
            ]
            
            all_news_items = []
            
            for query in search_queries:
                try:
                    encoded_query = urllib.parse.quote(query)
                    
                    urls = [
                        f"https://search.naver.com/search.naver?where=news&query={encoded_query}&sort=1&pd=1&ds=&de=",
                        f"https://finance.naver.com/item/news.naver?code={stock_code}",
                        f"https://search.naver.com/search.naver?where=news&query={encoded_query}&sort=0"
                    ]
                    
                    for url in urls:
                        try:
                            response = self.session.get(url, timeout=15)
                            response.raise_for_status()
                            
                            soup = BeautifulSoup(response.content, 'html.parser')
                            
                            news_selectors = [
                                'div.news_area',
                                'div.bx',
                                'dl.newsList',
                                'div.newsflash_item',
                                'li.newsList',
                                'div.section_news'
                            ]
                            
                            news_elements = []
                            for selector in news_selectors:
                                elements = soup.select(selector)
                                if elements:
                                    news_elements = elements[:15]
                                    break
                            
                            if not news_elements:
                                news_elements = soup.select('a[href*="news"], a[href*="article"]')[:10]
                            
                            for element in news_elements:
                                try:
                                    title_selectors = [
                                        'a.news_tit',
                                        'a.sh_blog_title', 
                                        '.title',
                                        'a.nclicks\\(fls\\.title\\)',
                                        'dt a',
                                        'strong.tit_news'
                                    ]
                                    
                                    title_elem = None
                                    for selector in title_selectors:
                                        title_elem = element.select_one(selector)
                                        if title_elem:
                                            break
                                    
                                    if not title_elem:
                                        title_elem = element.find('a') if element.name != 'a' else element
                                    
                                    if not title_elem:
                                        continue
                                        
                                    title = title_elem.get_text(strip=True)
                                    if not title or len(title) < 10:
                                        continue
                                        
                                    link = title_elem.get('href', '')
                                    if link and not link.startswith('http'):
                                        link = 'https://news.naver.com' + link
                                    
                                    date_selectors = [
                                        '.info_group .info',
                                        '.date',
                                        '.write_date',
                                        'span.date'
                                    ]
                                    
                                    date_text = ""
                                    for selector in date_selectors:
                                        date_elem = element.select_one(selector)
                                        if date_elem:
                                            date_text = date_elem.get_text(strip=True)
                                            break
                                    
                                    summary_selectors = [
                                        '.api_txt_lines',
                                        '.lede',
                                        '.summary',
                                        'dd'
                                    ]
                                    
                                    summary = ""
                                    for selector in summary_selectors:
                                        summary_elem = element.select_one(selector)
                                        if summary_elem:
                                            summary = summary_elem.get_text(strip=True)
                                            break
                                    
                                    combined_text = f"{title} {summary}".lower()
                                    stock_terms = [stock_name.lower(), stock_code]
                                    
                                    is_relevant = False
                                    for term in stock_terms:
                                        if term in combined_text:
                                            is_relevant = True
                                            break
                                    
                                    if not is_relevant and len(stock_name) >= 2:
                                        if stock_name[:2] in combined_text:
                                            is_relevant = True
                                    
                                    if is_relevant:
                                        news_item = {
                                            'title': title,
                                            'link': link,
                                            'date': date_text,
                                            'summary': summary if summary else title,
                                            'stock_name': stock_name,
                                            'stock_code': stock_code,
                                            'query_used': query,
                                            'source': 'naver_crawl'
                                        }
                                        
                                        if not any(existing['title'] == title for existing in all_news_items):
                                            all_news_items.append(news_item)
                                        
                                except Exception as e:
                                    continue
                                    
                        except Exception as e:
                            continue
                            
                    time.sleep(0.5)
                    
                except Exception as e:
                    continue
            
            unique_news = []
            seen_titles = set()
            
            for news in all_news_items:
                title_key = news['title'][:50]
                if title_key not in seen_titles:
                    seen_titles.add(title_key)
                    unique_news.append(news)
            
            final_news = unique_news  # ì „ì²´ ë‰´ìŠ¤ ë°˜í™˜ (10ê°œ ì œí•œ ì œê±°)
            
            self.logger.info(f"   ğŸ“° {stock_name} ë‰´ìŠ¤ {len(final_news)}ê°œ ìˆ˜ì§‘")
            
            if len(final_news) == 0:
                self.logger.info(f"   âš ï¸ {stock_name} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
            return final_news
            
        except Exception as e:
            self.logger.warning(f"   âš ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_material_with_weights(self, news_item: Dict) -> Tuple[str, List[str], float]:
        """ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì¬ë£Œ ë¶„ì„"""
        text = f"{news_item['title']} {news_item.get('summary', '')}".lower()
        
        found_materials = []
        material_type = "ì¬ë£Œì—†ìŒ"
        total_score = 0.0
        
        # ê° ì¬ë£Œ íƒ€ì…ë³„ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ì ìˆ˜ ê³„ì‚°
        type_scores = {}
        
        for mat_type, config in MATERIAL_KEYWORDS.items():
            keywords = config["keywords"]
            weight = config["weight"]
            matched_keywords = []
            type_score = 0.0
            
            for keyword in keywords:
                if keyword.lower() in text:
                    matched_keywords.append(keyword)
                    type_score += weight
            
            if matched_keywords:
                found_materials.extend(matched_keywords)
                type_scores[mat_type] = type_score
                total_score += type_score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¬ë£Œ íƒ€ì…ì„ ì£¼ ì¬ë£Œë¡œ ì„ ì •
        if type_scores:
            # ì¥ê¸° > ì¤‘ê¸° > ë‹¨ê¸° ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì ìš©
            priority_order = ["ì¥ê¸°ì¬ë£Œ", "ì¤‘ê¸°ì¬ë£Œ", "ë‹¨ê¸°ì¬ë£Œ"]
            for mat_type in priority_order:
                if mat_type in type_scores:
                    material_type = mat_type
                    break
        
        return material_type, found_materials, total_score
    
    def calculate_news_sentiment_score(self, news_items: List[Dict]) -> float:
        """ë‰´ìŠ¤ ê°ì • ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        positive_keywords = [
            "ìƒìŠ¹", "ì¦ê°€", "í˜¸ì¡°", "ê°œì„ ", "ì„±ì¥", "í™•ëŒ€", "ì‹ ê³ ê°€", "ëŒíŒŒ", "ìˆ˜í˜œ", "ê¸°ëŒ€",
            "ê¸ì •", "ìœ ë¦¬", "ê°•ì„¸", "ê¸‰ë“±", "ìƒìŠ¹ì„¸", "ë°˜ë“±", "íšŒë³µ", "ì„±ê³µ", "ì„ ì „", "ëŒ€ë°•"
        ]
        
        negative_keywords = [
            "í•˜ë½", "ê°ì†Œ", "ë¶€ì§„", "ì•…í™”", "ì¶•ì†Œ", "ì‹ ì €ê°€", "í•˜ë½ì„¸", "ê¸‰ë½", "í­ë½", 
            "ë¶€ì •", "ë¶ˆë¦¬", "ì•½ì„¸", "ìš°ë ¤", "ìœ„í—˜", "ì†ì‹¤", "ì ì", "ë¶€ì‹¤", "ìœ„ê¸°", "ì¶©ê²©"
        ]
        
        total_sentiment = 0.0
        total_words = 0
        
        for news in news_items:
            text = f"{news['title']} {news.get('summary', '')}".lower()
            words = text.split()
            total_words += len(words)
            
            for word in words:
                if any(pos in word for pos in positive_keywords):
                    total_sentiment += 1
                elif any(neg in word for neg in negative_keywords):
                    total_sentiment -= 1
        
        if total_words == 0:
            return 0.0
        
        # -1 ~ 1 ë²”ìœ„ë¡œ ì •ê·œí™”
        sentiment_score = total_sentiment / total_words
        return max(-1, min(1, sentiment_score))
    
    def analyze_stock_materials(self, stock_info: Dict) -> Dict:
        """ì¢…ëª©ë³„ ì¬ë£Œ ì¢…í•© ë¶„ì„ (ê°€ì¤‘ì¹˜ ì ìš©) - ì•ˆì „í•œ ì†ì„± ì ‘ê·¼"""
        # ì•ˆì „í•œ ì†ì„± ì ‘ê·¼
        stock_name = self.safe_get_attr(stock_info, 'name', 
                                    self.safe_get_attr(stock_info, 'ì¢…ëª©ëª…', ''))
        stock_code = self.safe_get_attr(stock_info, 'symbol', 
                                    self.safe_get_attr(stock_info, 'ì¢…ëª©ì½”ë“œ', ''))
        
        self.logger.info(f"\nğŸ” {stock_name} ({stock_code}) ì¬ë£Œ ë¶„ì„ ì¤‘...")
        
        # ì œì™¸ ëŒ€ìƒ ì¢…ëª© ì²´í¬
        if self.is_excluded_stock(stock_name, stock_code):
            return {
                'stock_info': stock_info,
                'material_summary': {
                    'primary_material': "ì œì™¸ì¢…ëª©",
                    'total_score': 0.0,
                    'weighted_score': 0.0,
                    'news_count': 0,
                    'material_keywords': [],
                    'sentiment_score': 0.0,
                    'excluded': True,
                    'exclude_reason': "ETF/ìš°ì„ ì£¼/íˆ¬ìì£¼ì˜ ì¢…ëª©"
                },
                'news_analysis': []
            }
        
        news_items = self.search_stock_news_naver(stock_name, stock_code)
        
        if not news_items:
            return {
                'stock_info': stock_info,
                'material_summary': {
                    'primary_material': "ì¬ë£Œì—†ìŒ",
                    'total_score': 0.0,
                    'weighted_score': 0.0,
                    'news_count': 0,
                    'material_keywords': [],
                    'sentiment_score': 0.0,
                    'excluded': False
                },
                'news_analysis': []
            }
        
        news_analysis = []
        all_materials = []
        total_score = 0.0
        
        for news in news_items:
            material_type, keywords, score = self.analyze_material_with_weights(news)
            
            analysis = {
                'title': news['title'],
                'date': news['date'],
                'material_type': material_type,
                'keywords': keywords,
                'score': score,
                'link': news.get('link', ''),
                'summary': news.get('summary', '')
            }
            
            news_analysis.append(analysis)
            all_materials.extend(keywords)
            total_score += score
            
            if material_type != "ì¬ë£Œì—†ìŒ":
                self.logger.info(f"   ğŸ“„ {material_type}: {news['title'][:50]}...")
                self.logger.info(f"      í‚¤ì›Œë“œ: {', '.join(keywords[:3])}{'...' if len(keywords) > 3 else ''}")
        
        # ì¬ë£Œ ì¹´ìš´íŠ¸
        material_counts = {}
        for analysis in news_analysis:
            mat_type = analysis['material_type']
            if mat_type != "ì¬ë£Œì—†ìŒ":
                material_counts[mat_type] = material_counts.get(mat_type, 0) + 1
        
        # ì£¼ìš” ì¬ë£Œ ê²°ì • (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
        primary_material = "ì¬ë£Œì—†ìŒ"
        if material_counts:
            # ì¥ê¸° > ì¤‘ê¸° > ë‹¨ê¸° ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„
            for mat_type in ["ì¥ê¸°ì¬ë£Œ", "ì¤‘ê¸°ì¬ë£Œ", "ë‹¨ê¸°ì¬ë£Œ"]:
                if mat_type in material_counts:
                    primary_material = mat_type
                    break
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        sentiment_score = self.calculate_news_sentiment_score(news_items)
        
        # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        weighted_score = total_score
        if sentiment_score > 0:
            weighted_score *= (1 + sentiment_score * 0.2)  # ê¸ì •ì  ê°ì • ë³´ë„ˆìŠ¤
        elif sentiment_score < 0:
            weighted_score *= (1 + sentiment_score * 0.1)  # ë¶€ì •ì  ê°ì • í˜ë„í‹°
        
        unique_keywords = list(set(all_materials))
        
        result = {
            'stock_info': stock_info,
            'material_summary': {
                'primary_material': primary_material,
                'total_score': total_score,
                'weighted_score': weighted_score,
                'news_count': len(news_items),
                'material_keywords': unique_keywords,
                'material_counts': material_counts,
                'sentiment_score': sentiment_score,
                'excluded': False
            },
            'news_analysis': news_analysis
        }
        
        self.logger.info(f"   âœ… ì¬ë£Œ ë¶„ì„ ì™„ë£Œ: {primary_material} (ê°€ì¤‘ì¹˜ ì ìˆ˜: {weighted_score:.2f})")
        return result
    
    def get_material_score_ranking(self, analysis_results: List[Dict]) -> List[Dict]:
        """ì¬ë£Œ ì ìˆ˜ë³„ ì¢…ëª© ìˆœìœ„ ì •ë ¬ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        valid_results = []
        
        for result in analysis_results:
            summary = result.get('material_summary', {})
            
            # ì œì™¸ ì¢…ëª©ì€ ìˆœìœ„ì—ì„œ ì œì™¸
            if summary.get('excluded', False):
                continue
            
            # ì¬ë£Œê°€ ìˆëŠ” ì¢…ëª©ë§Œ í¬í•¨
            if summary.get('primary_material') != "ì¬ë£Œì—†ìŒ" and summary.get('weighted_score', 0) > 0:
                result['final_score'] = summary.get('weighted_score', 0)
                valid_results.append(result)
        
        # ê°€ì¤‘ì¹˜ ì ìˆ˜ìˆœ ì •ë ¬
        sorted_results = sorted(valid_results, key=lambda x: x['final_score'], reverse=True)
        
        # ìˆœìœ„ ì¶”ê°€
        for i, result in enumerate(sorted_results, 1):
            result['material_rank'] = i
        
        return sorted_results
    
    def safe_get_attr(self, data, attr_name, default=None):
        """ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ ìœ í‹¸ë¦¬í‹°"""
        try:
            if isinstance(data, dict):
                return data.get(attr_name, default)
            else:
                return getattr(data, attr_name, default)
        except (AttributeError, TypeError):
            return default
    
    def get_news_analysis_summary(self, stock_name: str, stock_code: str) -> Dict:
        """ë‹¨ì¼ ì¢…ëª©ì˜ ë‰´ìŠ¤ ë¶„ì„ ìš”ì•½ - ì•ˆì „í•œ ì†ì„± ì ‘ê·¼"""
        stock_info = {
            'name': stock_name,
            'symbol': stock_code
        }
        
        analysis_result = self.analyze_stock_materials(stock_info)
        summary = analysis_result.get('material_summary', {})
        
        return {
            'has_material': summary.get('primary_material') != "ì¬ë£Œì—†ìŒ",
            'material_type': summary.get('primary_material'),
            'material_score': summary.get('weighted_score', 0),
            'news_count': summary.get('news_count', 0),
            'sentiment_score': summary.get('sentiment_score', 0),
            'keywords': summary.get('material_keywords', [])[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
            'excluded': summary.get('excluded', False)
        }
    async def analyze_symbol(self, symbol: str, name: str, strategy: str) -> Optional[AnalysisResult]:
        """ê°œë³„ ì¢…ëª© ë¶„ì„ - ì•ˆì „í•œ ë°ì´í„° ì „ë‹¬"""
        try:
            # 1. ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘
            stock_data = await self.data_collector.get_stock_info(symbol)
            if not stock_data:
                return None
            
            # 2. ë‰´ìŠ¤ ë¶„ì„ - ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
            try:
                # stock_dataê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
                news_data_input = {
                    'name': stock_data.get('name', name) if isinstance(stock_data, dict) else getattr(stock_data, 'name', name),
                    'symbol': stock_data.get('symbol', symbol) if isinstance(stock_data, dict) else getattr(stock_data, 'symbol', symbol)
                }
                news_data = self.news_collector.analyze_stock_materials(news_data_input)
            except Exception as e:
                self.logger.warning(f"âš ï¸ {symbol} ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨, ê±´ë„ˆë›°ê¸°: {e}")
                news_data = None
            
            # 3. ì¢…í•© ë¶„ì„
            analysis_result = await self.analysis_engine.analyze_comprehensive(
                symbol=symbol,
                name=name,
                stock_data=stock_data,
                news_data=news_data,
                strategy=strategy
            )
            
            # 4. ì „ëµë³„ ì‹ í˜¸ ìƒì„±
            strategy_obj = self.strategies.get(strategy)
            if not strategy_obj:
                self.logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ: {strategy}, ì‚¬ìš© ê°€ëŠ¥: {list(self.strategies.keys())}")
                return None
            
            signals = await strategy_obj.generate_signals(stock_data, analysis_result)
            
            # 5. ë¦¬ìŠ¤í¬ í‰ê°€
            risk_level = await self._evaluate_risk(stock_data, analysis_result)
            
            # 6. ë§¤ìˆ˜/ë§¤ë„ ê°€ê²© ê³„ì‚°
            entry_price, stop_loss, take_profit = await self._calculate_trade_prices(
                stock_data, signals, strategy_obj
            )
            
            # 7. ê²°ê³¼ ìƒì„±
            result = AnalysisResult(
                symbol=symbol,
                name=name,
                score=analysis_result.get('comprehensive_score', 0),
                signals=signals,
                analysis_time=datetime.now(),
                strategy=strategy,
                recommendation=self._get_recommendation(analysis_result, signals),
                risk_level=risk_level,
                entry_price=entry_price,
                stop_loss=stop_loss,
                take_profit=take_profit
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {symbol} ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    async def analyze_with_gemini(self, stock_name: str, stock_code: str, news_data: List[Dict] = None) -> Dict:
        """Gemini AIë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ë¶„ì„"""
        try:
            if not self.gemini_analyzer:
                self.logger.warning("âš ï¸ Gemini ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©")
                return self._get_default_gemini_analysis()
            
            # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìˆ˜ì§‘
            if not news_data:
                news_data = self.search_stock_news_naver(stock_name, stock_code)
            
            if not news_data:
                # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ë” ì ê·¹ì ì¸ ê²€ìƒ‰ ì‹œë„
                self.logger.warning(f"âš ï¸ {stock_name} ì´ˆê¸° ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨, ì¶”ê°€ ê²€ìƒ‰ ì‹œë„ ì¤‘...")
                
                # ëŒ€ì²´ ê²€ìƒ‰ì–´ë¡œ ë‹¤ì‹œ ì‹œë„
                alternative_searches = [
                    stock_code,  # ì¢…ëª©ì½”ë“œë¡œ ê²€ìƒ‰
                    f"{stock_name} ì£¼ê°€",  # ì£¼ê°€ í‚¤ì›Œë“œ ì¶”ê°€
                    f"{stock_name} ì‹¤ì ",  # ì‹¤ì  í‚¤ì›Œë“œ ì¶”ê°€
                    f"{stock_name} ê³µì‹œ"   # ê³µì‹œ í‚¤ì›Œë“œ ì¶”ê°€
                ]
                
                for search_term in alternative_searches:
                    try:
                        news_data = self.search_stock_news_naver(search_term, stock_code)
                        if news_data:
                            self.logger.info(f"âœ… {stock_name} ëŒ€ì²´ ê²€ìƒ‰ì–´ '{search_term}'ìœ¼ë¡œ ë‰´ìŠ¤ {len(news_data)}ê±´ ë°œê²¬")
                            break
                    except Exception as e:
                        self.logger.debug(f"ëŒ€ì²´ ê²€ìƒ‰ '{search_term}' ì‹¤íŒ¨: {e}")
                        continue
                
                if not news_data:
                    self.logger.warning(f"âš ï¸ {stock_name}({stock_code}) ëª¨ë“  ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œë„ ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©")
                    return self._get_default_gemini_analysis_with_context(stock_name, stock_code)
            
            # Geminië¡œ ê°ì„± ë¶„ì„
            sentiment_result = await self.gemini_analyzer.analyze_news_sentiment(
                stock_code, stock_name, news_data
            )
            
            # Geminië¡œ ì‹œì¥ ì˜í–¥ë„ ë¶„ì„
            impact_result = await self.gemini_analyzer.analyze_market_impact(
                stock_code, stock_name, news_data
            )
            
            # ê²°ê³¼ í†µí•©
            combined_analysis = {
                'symbol': stock_code,
                'name': stock_name,
                'news_count': len(news_data),
                'analysis_timestamp': datetime.now().isoformat(),
                
                # ê°ì„± ë¶„ì„ ê²°ê³¼
                'sentiment': {
                    'overall_sentiment': sentiment_result.get('sentiment', 'NEUTRAL'),
                    'confidence': sentiment_result.get('confidence', 0.5),
                    'overall_score': sentiment_result.get('overall_score', 50),
                    'positive_factors': sentiment_result.get('positive_factors', []),
                    'negative_factors': sentiment_result.get('negative_factors', []),
                    'key_keywords': sentiment_result.get('key_keywords', []),
                    'short_term_outlook': sentiment_result.get('short_term_outlook', ''),
                    'medium_term_outlook': sentiment_result.get('medium_term_outlook', ''),
                    'summary': sentiment_result.get('summary', '')
                },
                
                # ì‹œì¥ ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
                'market_impact': {
                    'impact_level': impact_result.get('impact_level', 'MEDIUM'),
                    'impact_score': impact_result.get('impact_score', 50),
                    'duration': impact_result.get('duration', 'MEDIUM_TERM'),
                    'price_direction': impact_result.get('price_direction', 'NEUTRAL'),
                    'volatility_expected': impact_result.get('volatility_expected', 'MEDIUM'),
                    'trading_volume_impact': impact_result.get('trading_volume_impact', 'NORMAL'),
                    'sector_impact': impact_result.get('sector_impact', ''),
                    'key_risks': impact_result.get('key_risks', []),
                    'catalysts': impact_result.get('catalysts', []),
                    'target_price_change': impact_result.get('target_price_change', '0%'),
                    'recommendation': impact_result.get('recommendation', 'HOLD')
                },
                
                # ì¢…í•© í‰ê°€
                'final_assessment': {
                    'investment_grade': self._calculate_investment_grade(sentiment_result, impact_result),
                    'risk_level': self._assess_risk_level(sentiment_result, impact_result),
                    'trading_strategy': self._suggest_trading_strategy(sentiment_result, impact_result),
                    'key_points': self._extract_key_points(sentiment_result, impact_result)
                }
            }
            
            self.logger.info(f"âœ… {stock_name} Gemini ë¶„ì„ ì™„ë£Œ - ê°ì„±: {sentiment_result.get('sentiment', 'NEUTRAL')}, ì˜í–¥ë„: {impact_result.get('impact_level', 'MEDIUM')}")
            return combined_analysis
            
        except Exception as e:
            self.logger.error(f"âŒ {stock_name} Gemini ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_default_gemini_analysis()
    
    def _get_default_gemini_analysis(self) -> Dict:
        """ê¸°ë³¸ Gemini ë¶„ì„ ê²°ê³¼"""
        return self._get_default_gemini_analysis_with_context("UNKNOWN", "UNKNOWN")
    
    def _get_default_gemini_analysis_with_context(self, stock_name: str, stock_code: str) -> Dict:
        """ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê¸°ë³¸ Gemini ë¶„ì„ ê²°ê³¼"""
        return {
            'symbol': stock_code,
            'name': stock_name,
            'news_count': 0,
            'analysis_timestamp': datetime.now().isoformat(),
            'data_status': 'NO_NEWS_DATA',
            'sentiment': {
                'overall_sentiment': 'NEUTRAL',
                'confidence': 0.3,  # ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë‚®ì€ ì‹ ë¢°ë„
                'overall_score': 50,
                'positive_factors': ['ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€'],
                'negative_factors': ['ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€'],
                'key_keywords': [],
                'short_term_outlook': f'{stock_name} ë‰´ìŠ¤ ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ì¤‘ë¦½ì  ì „ë§',
                'medium_term_outlook': f'{stock_name} ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ í›„ ì¬ë¶„ì„ í•„ìš”',
                'summary': f'{stock_name}({stock_code}) ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ AI ë¶„ì„ ì œí•œ'
            },
            'market_impact': {
                'impact_level': 'LOW',  # ì •ë³´ ë¶€ì¡±ì‹œ ë‚®ì€ ì˜í–¥ë„
                'impact_score': 40,     # ë³´ìˆ˜ì  ì ìˆ˜
                'duration': 'SHORT_TERM',
                'price_direction': 'NEUTRAL',
                'volatility_expected': 'LOW',
                'trading_volume_impact': 'NORMAL',
                'sector_impact': 'ì •ë³´ ë¶€ì¡±',
                'key_risks': [],
                'catalysts': [],
                'target_price_change': '0%',
                'recommendation': 'HOLD'
            },
            'final_assessment': {
                'investment_grade': 'C',
                'risk_level': 'MEDIUM',
                'trading_strategy': 'WAIT_AND_SEE',
                'key_points': ['ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ì‹ ì¤‘í•œ ì ‘ê·¼ ê¶Œì¥']
            }
        }
    
    def _calculate_investment_grade(self, sentiment_result: Dict, impact_result: Dict) -> str:
        """íˆ¬ì ë“±ê¸‰ ê³„ì‚°"""
        sentiment_score = sentiment_result.get('overall_score', 50)
        impact_score = impact_result.get('impact_score', 50)
        
        combined_score = (sentiment_score + impact_score) / 2
        
        if combined_score >= 85:
            return 'A+'
        elif combined_score >= 80:
            return 'A'
        elif combined_score >= 75:
            return 'A-'
        elif combined_score >= 70:
            return 'B+'
        elif combined_score >= 65:
            return 'B'
        elif combined_score >= 60:
            return 'B-'
        elif combined_score >= 55:
            return 'C+'
        elif combined_score >= 50:
            return 'C'
        elif combined_score >= 45:
            return 'C-'
        elif combined_score >= 40:
            return 'D+'
        elif combined_score >= 35:
            return 'D'
        else:
            return 'D-'
    
    def _assess_risk_level(self, sentiment_result: Dict, impact_result: Dict) -> str:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ í‰ê°€"""
        volatility = impact_result.get('volatility_expected', 'MEDIUM')
        confidence = sentiment_result.get('confidence', 0.5)
        
        if volatility == 'VERY_HIGH' or confidence < 0.3:
            return 'HIGH'
        elif volatility == 'HIGH' or confidence < 0.5:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _suggest_trading_strategy(self, sentiment_result: Dict, impact_result: Dict) -> str:
        """ë§¤ë§¤ ì „ëµ ì œì•ˆ"""
        sentiment = sentiment_result.get('sentiment', 'NEUTRAL')
        impact_level = impact_result.get('impact_level', 'MEDIUM')
        price_direction = impact_result.get('price_direction', 'NEUTRAL')
        
        if sentiment in ['VERY_POSITIVE', 'POSITIVE'] and impact_level in ['VERY_HIGH', 'HIGH']:
            if price_direction in ['STRONG_UP', 'UP']:
                return 'AGGRESSIVE_BUY'
            else:
                return 'MODERATE_BUY'
        elif sentiment in ['VERY_NEGATIVE', 'NEGATIVE'] and impact_level in ['VERY_HIGH', 'HIGH']:
            if price_direction in ['STRONG_DOWN', 'DOWN']:
                return 'AGGRESSIVE_SELL'
            else:
                return 'MODERATE_SELL'
        elif sentiment == 'NEUTRAL' or impact_level in ['LOW', 'VERY_LOW']:
            return 'WAIT_AND_SEE'
        else:
            return 'CAUTIOUS_APPROACH'
    
    def _extract_key_points(self, sentiment_result: Dict, impact_result: Dict) -> List[str]:
        """í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        key_points = []
        
        # ê¸ì •ì  ìš”ì¸
        positive_factors = sentiment_result.get('positive_factors', [])
        if positive_factors:
            key_points.append(f"ê¸ì • ìš”ì¸: {', '.join(positive_factors[:3])}")
        
        # ë¶€ì •ì  ìš”ì¸
        negative_factors = sentiment_result.get('negative_factors', [])
        if negative_factors:
            key_points.append(f"ìš°ë ¤ ìš”ì¸: {', '.join(negative_factors[:3])}")
        
        # ìƒìŠ¹ ì´‰ë§¤
        catalysts = impact_result.get('catalysts', [])
        if catalysts:
            key_points.append(f"ìƒìŠ¹ ì´‰ë§¤: {', '.join(catalysts[:2])}")
        
        # ì£¼ìš” ë¦¬ìŠ¤í¬
        risks = impact_result.get('key_risks', [])
        if risks:
            key_points.append(f"ì£¼ìš” ë¦¬ìŠ¤í¬: {', '.join(risks[:2])}")
        
        # ì˜ˆìƒ ì£¼ê°€ ë³€ë™
        price_change = impact_result.get('target_price_change', '0%')
        if price_change != '0%':
            key_points.append(f"ì˜ˆìƒ ë³€ë™ë¥ : {price_change}")
        
        return key_points if key_points else ['íŠ¹ë³„í•œ ì´ìŠˆ ì—†ìŒ']